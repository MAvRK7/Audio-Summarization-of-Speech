# ğŸ™ï¸ Multiâ€‘Speaker Speech Processing in Noisy Environments

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)]()
[![PyTorch](https://img.shields.io/badge/Framework-PyTorch-orange)]()
[![Conference](https://img.shields.io/badge/Accepted%20at-SPIN%202025-blueviolet)]()
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)]()

---

## ğŸ“Œ Overview
This is a hybrid speech processing pipeline designed to:
1. **Separate** overlapping speech from noisy, multiâ€‘speaker audio
2. **Transcribe** each speakerâ€™s voice
3. **Summarize** the conversation

The system integrates:
- **SepFormer** â€” transformerâ€‘based speech separation
- **ConvTasNet** â€” convolutional timeâ€‘domain separation
- **Adaptive noise reduction** â€” to suppress background noise and enhance intelligibility
- **Google Speechâ€‘toâ€‘Text API** â€” for transcription
- **BART (fineâ€‘tuned)** â€” for abstractive summarization

---

## ğŸ›° Conference & Publication
- **Accepted at**: *International Conference on Signal Processing and Integrated Networks (SPIN 2025)*
- **To be published in**: *Lecture Notes in Electrical Engineering* (Springer)

---

## ğŸ§ Example Audio

| File | Description |
|------|-------------|
| `mixed_audio.mp3` | Original noisy, overlapping twoâ€‘speaker audio |
| `separated_audio_1.wav` | Speaker 1 isolated |
| `separated_audio_2.wav` | Speaker 2 isolated |

---

## ğŸ§ª Methodology

**Pipeline Flow**:

<img width="203" height="506" alt="image" src="https://github.com/user-attachments/assets/dfdb6211-f177-42ac-9563-9411ed4781c1" />


---

## ğŸ“Š Performance

| Metric | Score (avg) |
|--------|-------------|
| SDR (Signalâ€‘toâ€‘Distortion Ratio) | 24.6 |
| SIR (Signalâ€‘toâ€‘Interference Ratio) | 24.5 |
| SAR (Signalâ€‘toâ€‘Artifacts Ratio) | 24.5 |

---

## ğŸš€ Key Features
- **Hybrid separation**: Combines transformer and convolutional models
- **Noiseâ€‘aware**: Adaptive filtering for realâ€‘world conditions
- **Endâ€‘toâ€‘end**: From raw noisy audio to summarized conversation
- **Lightweight**: No significant increase in computational cost

---

## ğŸ’¡ Skills Demonstrated
Speech separation (SepFormer, ConvTasNet)

Noise reduction algorithms

Speechâ€‘toâ€‘text integration

Abstractive summarization (BART fineâ€‘tuning)

Audio signal processing & evaluation metrics

Endâ€‘toâ€‘end ML pipeline design

---

## ğŸ™ Acknowledgments
SepFormer & ConvTasNet authors

Google Speechâ€‘toâ€‘Text API

BART model (Hugging Face Transformers)

SPIN 2025 Conference Committee
